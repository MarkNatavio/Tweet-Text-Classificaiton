{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "092faea5",
   "metadata": {},
   "source": [
    "<h2>\n",
    "CSC 44700 - Introduction to Machine Learning<br/>\n",
    "May 22, 2022<br/>\n",
    "Professor: Erik Grimmelmann<br/>\n",
    "Mark Natavio <br/>\n",
    "Final Project Codes\n",
    "</h2>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "# Logistic Regession\n",
    "\n",
    "For section, I will be using a Logistic regrssion model for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2505e487",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3608eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e91c8d",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e704bbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target          ID                          Date      Flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              User                                               Text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/marknatavio/Desktop/Final project/Codes/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-15\",names=['Target','ID','Date','Flag','User','Text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5bc471",
   "metadata": {},
   "source": [
    "#### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4297c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target values:\n",
      "[0 4]\n",
      "\n",
      "Target counts:\n",
      "0    800000\n",
      "4    800000\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Count of null values per column:\n",
      "Target    0\n",
      "ID        0\n",
      "Date      0\n",
      "Flag      0\n",
      "User      0\n",
      "Text      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Target values:\\n\"+str(df['Target'].unique()))\n",
    "print(\"\\nTarget counts:\\n\"+str(df['Target'].value_counts()))\n",
    "print(\"\\nCount of null values per column:\\n\"+str(df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7cba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'].values\n",
    "Y = df['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d504a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\",\n",
       "       \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\",\n",
       "       '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds',\n",
       "       ..., 'Are you ready for your MoJo Makeover? Ask me for details ',\n",
       "       'Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur ',\n",
       "       'happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1162c986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81decf9f",
   "metadata": {},
   "source": [
    "#### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96b8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6285e96",
   "metadata": {},
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ded7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(x_train)\n",
    "\n",
    "X_train = vect.transform(x_train)\n",
    "X_test = vect.transform(x_test)\n",
    "#print(x_train[4])\n",
    "#print(X_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24afcc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56129)\t1\n",
      "  (0, 57447)\t1\n",
      "  (0, 126962)\t1\n",
      "  (0, 129411)\t1\n",
      "  (0, 132556)\t1\n",
      "  (0, 142883)\t1\n",
      "  (0, 226884)\t1\n",
      "  (0, 252021)\t1\n",
      "  (0, 256925)\t1\n",
      "  (0, 257741)\t1\n",
      "  (0, 257883)\t1\n",
      "  (0, 433510)\t1\n",
      "  (0, 455368)\t1\n",
      "  (0, 467486)\t1\n",
      "  (0, 486108)\t1\n",
      "  (0, 501574)\t1\n",
      "  (0, 517177)\t1\n",
      "  (0, 520059)\t1\n",
      "  (0, 528806)\t1\n",
      "  (0, 558368)\t1\n",
      "  (0, 562011)\t1\n",
      "  (0, 562867)\t1\n",
      "  (0, 566030)\t1\n",
      "  (0, 566811)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d5e3a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          257883  \n",
      "was         558368  \n",
      "rainy       433510  \n",
      "and         57447   \n",
      "cloudy      129411  \n",
      "in          252021  \n",
      "the         517177  \n",
      "Windy       566030  \n",
      "City        126962  \n",
      "today       528806  \n",
      "amp         56129   \n",
      "WF          562011  \n",
      "customers   142883  \n",
      "had         226884  \n",
      "some        486108  \n",
      "serious     467486  \n",
      "SAD         455368  \n",
      "issues      257741  \n",
      "with        566811  \n",
      "them        520059  \n",
      "when        562867  \n",
      "is          256925  \n",
      "summer      501574  \n",
      "coming      132556  \n"
     ]
    }
   ],
   "source": [
    "symbols = \",.!?/&-:;@'...\"\n",
    "\"[\"+\"\\\\\".join(symbols)+\"]\"\n",
    "\n",
    "s = x_train[0]\n",
    "s = ' '.join(x for x in re.split(\"[\"+\"\\\\\".join(symbols)+\"]\", s) if x)\n",
    "\n",
    "for x in s.split():\n",
    "    if len(x) > 1:\n",
    "        print(f\"{x : <10}{vect.vocabulary_[x.lower()] : ^10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5220696e",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd19d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marknatavio/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5796fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80031875\n"
     ]
    }
   ],
   "source": [
    "score = classifier.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77bf5689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126496</td>\n",
       "      <td>33825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30073</td>\n",
       "      <td>129606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       4\n",
       "0  126496   33825\n",
       "4   30073  129606"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = df['Target'].unique()\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels = unique)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=unique, columns=unique)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc1bc9a",
   "metadata": {},
   "source": [
    "#### Count Vectorization and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35c886e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marknatavio/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983125\n"
     ]
    }
   ],
   "source": [
    "NB = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "NB.fit(x_train, y_train)\n",
    "score = NB.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fcb8ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125626</td>\n",
       "      <td>34695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29845</td>\n",
       "      <td>129834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       4\n",
       "0  125626   34695\n",
       "4   29845  129834"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = df['Target'].unique()\n",
    "y_pred = NB.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels = unique)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=unique, columns=unique)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94062387",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorization and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "861dc526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marknatavio/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.802515625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127017</td>\n",
       "      <td>33304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29891</td>\n",
       "      <td>129788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       4\n",
       "0  127017   33304\n",
       "4   29891  129788"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "NB.fit(x_train, y_train)\n",
    "score = NB.score(x_test, y_test)\n",
    "print(score)\n",
    "\n",
    "unique = df['Target'].unique()\n",
    "y_pred = NB.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels = unique)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=unique, columns=unique)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533caeec",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "Here I will be using Naive bayes for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f07f13",
   "metadata": {},
   "source": [
    "#### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c13e3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba1c18",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "085155c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target          ID                          Date      Flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              User                                               Text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/marknatavio/Desktop/Final project/Codes/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-15\",names=['Target','ID','Date','Flag','User','Text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b31f7",
   "metadata": {},
   "source": [
    "#### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d03d11a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target values:\n",
      "[0 4]\n",
      "\n",
      "Target counts:\n",
      "0    800000\n",
      "4    800000\n",
      "Name: Target, dtype: int64\n",
      "\n",
      "Count of null values per column:\n",
      "Target    0\n",
      "ID        0\n",
      "Date      0\n",
      "Flag      0\n",
      "User      0\n",
      "Text      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "targets = df['Target'].unique()\n",
    "print(\"Target values:\\n\"+str(targets))\n",
    "print(\"\\nTarget counts:\\n\"+str(df['Target'].value_counts()))\n",
    "print(\"\\nCount of null values per column:\\n\"+str(df.isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c784246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'].values\n",
    "Y = df['Target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f789814a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\",\n",
       "       \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\",\n",
       "       '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds',\n",
       "       ..., 'Are you ready for your MoJo Makeover? Ask me for details ',\n",
       "       'Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur ',\n",
       "       'happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f1bec42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773c932",
   "metadata": {},
   "source": [
    "#### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f104a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22f6c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@kgasso Jeez...  Not that it would have made it easier either way...\n"
     ]
    }
   ],
   "source": [
    "print(x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af931c47",
   "metadata": {},
   "source": [
    "#### Count Vectorization & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f0bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780703125\n"
     ]
    }
   ],
   "source": [
    "NB = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "NB.fit(x_train, y_train)\n",
    "score = NB.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36e6262c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131110</td>\n",
       "      <td>29211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40964</td>\n",
       "      <td>118715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       4\n",
       "0  131110   29211\n",
       "4   40964  118715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = df['Target'].unique()\n",
    "y_pred = NB.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels = unique)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=unique, columns=unique)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33d6d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780703125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131110</td>\n",
       "      <td>29211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40964</td>\n",
       "      <td>118715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       4\n",
       "0  131110   29211\n",
       "4   40964  118715"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(x_train)\n",
    "\n",
    "X_train = vect.transform(x_train)\n",
    "X_test = vect.transform(x_test)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(score)\n",
    "\n",
    "unique = df['Target'].unique()\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels = unique)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=unique, columns=unique)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e99b758",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorization & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a14e1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773678125\n"
     ]
    }
   ],
   "source": [
    "NB = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "NB.fit(x_train, y_train)\n",
    "score = NB.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb8756df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131229</td>\n",
       "      <td>29092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43331</td>\n",
       "      <td>116348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       4\n",
       "0  131229   29092\n",
       "4   43331  116348"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = df['Target'].unique()\n",
    "y_pred = NB.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels = unique)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=unique, columns=unique)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ba370",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# TensorFlow Neural Network\n",
    "\n",
    "Here I will be using Naive bayes for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "923fe099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import rcParams\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import string\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c9f3492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flag</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target          ID                          Date      Flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    User                                               Text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/marknatavio/Desktop/Final project/Codes/training.1600000.processed.noemoticon.csv', encoding = \"ISO-8859-15\",names=['Target','ID','Date','Flag','User','Text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d0dae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[[\"Text\",\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fef41eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Target\"][data[\"Target\"]==4]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e80606e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = data[data[\"Target\"]==1].iloc[:int(20000)]\n",
    "data_neg = data[data[\"Target\"]==0].iloc[:int(20000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "321b240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_pos, data_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "777eb952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Text\"]=data[\"Text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "759f63f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "331c82e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000                love @health4uandpets u guys r best!!\n",
       "800001    im meeting one besties tonight! cant wait!! - ...\n",
       "800002    @darealsunisakim thanks twitter add, sunisa! g...\n",
       "800003    sick really cheap hurts much eat real food plu...\n",
       "800004                      @lovesbrooklyn2 effect everyone\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stop)\n",
    "\n",
    "def clean_words(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in stop_words])\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: clean_words(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db4556f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000                   love health4uandpets u guys r best\n",
       "800001    im meeting one besties tonight cant wait  girl...\n",
       "800002    darealsunisakim thanks twitter add sunisa got ...\n",
       "800003    sick really cheap hurts much eat real food plu...\n",
       "800004                       lovesbrooklyn2 effect everyone\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations = string.punctuation\n",
    "\n",
    "def clean_punc(text):\n",
    "    return text.translate(str.maketrans('','', punctuations))\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: clean_punc(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c249ea66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000                   love health4uandpets u guys r best\n",
       "800001    im meting one besties tonight cant wait girl talk\n",
       "800002    darealsunisakim thanks twiter ad sunisa got me...\n",
       "800003    sick realy cheap hurts much eat real fod plus ...\n",
       "800004                         lovesbroklyn2 efect everyone\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_repeats(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: clean_repeats(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfd4dec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000                   love health4uandpets u guys r best\n",
       "800001    im meting one besties tonight cant wait girl talk\n",
       "800002    darealsunisakim thanks twiter ad sunisa got me...\n",
       "800003    sick realy cheap hurts much eat real fod plus ...\n",
       "800004                         lovesbroklyn2 efect everyone\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_email(text):\n",
    "    return re.sub('@[^\\s]+',' ', text)\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: clean_email(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22044f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000                   love health4uandpets u guys r best\n",
       "800001    im meting one besties tonight cant wait girl talk\n",
       "800002    darealsunisakim thanks twiter ad sunisa got me...\n",
       "800003    sick realy cheap hurts much eat real fod plus ...\n",
       "800004                         lovesbroklyn2 efect everyone\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_URLs(text):\n",
    "    return re.sub('((www\\.[^\\s]+) | (https?://[^\\s]+))','',text)\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: clean_URLs(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a10f47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000                    love healthuandpets u guys r best\n",
       "800001    im meting one besties tonight cant wait girl talk\n",
       "800002    darealsunisakim thanks twiter ad sunisa got me...\n",
       "800003    sick realy cheap hurts much eat real fod plus ...\n",
       "800004                          lovesbroklyn efect everyone\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_nums(text):\n",
    "    return re.sub('[0-9]+','',text)\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: clean_nums(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb0801",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2140d66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000             [love, healthuandpets, u, guys, r, best]\n",
       "800001    [im, meting, one, besties, tonight, cant, wait...\n",
       "800002    [darealsunisakim, thanks, twiter, ad, sunisa, ...\n",
       "800003    [sick, realy, cheap, hurts, much, eat, real, f...\n",
       "800004                      [lovesbroklyn, efect, everyone]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = RegexpTokenizer(r'\\w+')\n",
    "data[\"Text\"] = data[\"Text\"].apply(token.tokenize)\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb21f6c",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97ee5818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000               [love, healthuandpet, u, guy, r, best]\n",
       "800001    [im, mete, one, besti, tonight, cant, wait, gi...\n",
       "800002    [darealsunisakim, thank, twiter, ad, sunisa, g...\n",
       "800003    [sick, reali, cheap, hurt, much, eat, real, fo...\n",
       "800004                       [lovesbroklyn, efect, everyon]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    return [st.stem(word) for word in text]\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: stemming(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442f159",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32541f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/marknatavio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "800000               [love, healthuandpet, u, guy, r, best]\n",
       "800001    [im, mete, one, besti, tonight, cant, wait, gi...\n",
       "800002    [darealsunisakim, thank, twiter, ad, sunisa, g...\n",
       "800003    [sick, reali, cheap, hurt, much, eat, real, fo...\n",
       "800004                       [lovesbroklyn, efect, everyon]\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(text):\n",
    "    return [lm.lemmatize(word) for word in text]\n",
    "\n",
    "data[\"Text\"] = data[\"Text\"].apply(lambda text: lemmatizing(text))\n",
    "data[\"Text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6558de",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d10fde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Text\"]\n",
    "y = data[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d89fccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "tok = Tokenizer(num_words=2000)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11c459da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(sequences_matrix, y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5720d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_based_model(): #Defined tensorflow_based_model function for training tenforflow based model\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(2000,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer) \n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "335d98cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 00:15:14.004288: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tensorflow_based_model() # here we are calling the function of created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88d8d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b41e2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "360/360 [==============================] - 123s 334ms/step - loss: 0.5686 - accuracy: 0.7002 - val_loss: 0.5264 - val_accuracy: 0.7394\n",
      "Epoch 2/6\n",
      "360/360 [==============================] - 121s 336ms/step - loss: 0.5043 - accuracy: 0.7557 - val_loss: 0.5261 - val_accuracy: 0.7387\n",
      "Epoch 3/6\n",
      "360/360 [==============================] - 120s 333ms/step - loss: 0.5010 - accuracy: 0.7594 - val_loss: 0.5251 - val_accuracy: 0.7397\n",
      "Epoch 4/6\n",
      "360/360 [==============================] - 132s 368ms/step - loss: 0.4731 - accuracy: 0.7753 - val_loss: 0.5319 - val_accuracy: 0.7378\n",
      "Epoch 5/6\n",
      "360/360 [==============================] - 131s 364ms/step - loss: 0.4606 - accuracy: 0.7806 - val_loss: 0.5446 - val_accuracy: 0.7347\n",
      "Epoch 6/6\n",
      "360/360 [==============================] - 129s 357ms/step - loss: 0.4498 - accuracy: 0.7881 - val_loss: 0.5565 - val_accuracy: 0.7303\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,Y_train,batch_size=80,epochs=6, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f43505d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 11s 43ms/step - loss: 0.5339 - accuracy: 0.7440\n"
     ]
    }
   ],
   "source": [
    "accr1 = model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9e56295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7440000176429749\n"
     ]
    }
   ],
   "source": [
    "print(accr1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588d51a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
